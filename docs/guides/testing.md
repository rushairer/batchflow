# BatchFlow æµ‹è¯•æŒ‡å—

## ğŸ“‹ æµ‹è¯•ä½“ç³»æ¦‚è§ˆ

BatchFlow é‡‡ç”¨å¤šå±‚æ¬¡æµ‹è¯•ç­–ç•¥ï¼Œç¡®ä¿ä»£ç è´¨é‡å’Œç³»ç»Ÿç¨³å®šæ€§ï¼š

- **å•å…ƒæµ‹è¯•**ï¼šæ ¸å¿ƒé€»è¾‘å’Œç»„ä»¶æµ‹è¯•
- **é›†æˆæµ‹è¯•**ï¼šå¤šæ•°æ®åº“ç«¯åˆ°ç«¯æµ‹è¯•  
- **æ€§èƒ½æµ‹è¯•**ï¼šå‹åŠ›æµ‹è¯•å’ŒåŸºå‡†æµ‹è¯•
- **ç›‘æ§æµ‹è¯•**ï¼šæŒ‡æ ‡æ”¶é›†å’Œå¯è§†åŒ–éªŒè¯

## ğŸ§ª å•å…ƒæµ‹è¯•

### è¿è¡Œå•å…ƒæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•
go test -v ./...

# è¿è¡Œç‰¹å®šåŒ…çš„æµ‹è¯•
go test -v ./drivers/mysql
go test -v ./drivers/postgresql
go test -v ./drivers/sqlite
go test -v ./drivers/redis

# è¿è¡Œæµ‹è¯•è¦†ç›–ç‡åˆ†æ
go test -cover -coverprofile=coverage.out ./...
go tool cover -html=coverage.out -o coverage.html

# æŸ¥çœ‹è¦†ç›–ç‡æŠ¥å‘Š
open coverage.html  # macOS
xdg-open coverage.html  # Linux
```

### æ ¸å¿ƒæµ‹è¯•ç”¨ä¾‹

#### BatchFlow æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•

```go
func TestBatchFlowBasicOperations(t *testing.T) {
    // æµ‹è¯•åŸºæœ¬çš„æ‰¹é‡æ’å…¥åŠŸèƒ½
    ctx := context.Background()
    executor := mock.NewMockExecutor()
    batchFlow := batchflow.NewBatchFlow(ctx, 100, 10, 100*time.Millisecond, executor)
    defer batchFlow.Close()
    
    schema := batchflow.NewSQLSchema("test_table", batchflow.ConflictIgnoreOperationConfig, "id", "name")
    
    // æäº¤æµ‹è¯•æ•°æ®
    for i := 0; i < 50; i++ {
        request := batchflow.NewRequest(schema).
            SetInt64("id", int64(i)).
            SetString("name", fmt.Sprintf("test_%d", i))
        
        err := batchFlow.Submit(ctx, request)
        assert.NoError(t, err)
    }
    
    // éªŒè¯æ‰§è¡Œç»“æœ
    assert.Equal(t, 50, executor.GetProcessedCount())
}
```

#### æ•°æ®åº“é©±åŠ¨æµ‹è¯•

```go
func TestMySQLDriver(t *testing.T) {
    db := setupTestDB(t, "mysql")
    defer db.Close()
    
    executor := batchflow.NewSQLThrottledBatchExecutorWithDriver(db, batchflow.DefaultMySQLDriver)
    
    // æµ‹è¯•æ‰¹é‡æ’å…¥
    schema := batchflow.NewSQLSchema("test_users", batchflow.ConflictIgnoreOperationConfig, 
        "id", "name", "email")
    
    data := []map[string]any{
        {"id": 1, "name": "Alice", "email": "alice@example.com"},
        {"id": 2, "name": "Bob", "email": "bob@example.com"},
    }
    
    err := executor.ExecuteBatch(context.Background(), schema, data)
    assert.NoError(t, err)
    
    // éªŒè¯æ•°æ®æ’å…¥
    count := getRecordCount(t, db, "test_users")
    assert.Equal(t, 2, count)
}
```

### Mock æµ‹è¯•å·¥å…·

```go
// test/mock/executor.go
type MockExecutor struct {
    processedBatches []BatchData
    shouldFail       bool
    mu               sync.Mutex
}

func (m *MockExecutor) ExecuteBatch(ctx context.Context, schema *Schema, data []map[string]any) error {
    m.mu.Lock()
    defer m.mu.Unlock()
    
    if m.shouldFail {
        return errors.New("mock execution failed")
    }
    
    m.processedBatches = append(m.processedBatches, BatchData{
        Schema: schema,
        Data:   data,
        Time:   time.Now(),
    })
    
    return nil
}

func (m *MockExecutor) GetProcessedCount() int {
    m.mu.Lock()
    defer m.mu.Unlock()
    
    total := 0
    for _, batch := range m.processedBatches {
        total += len(batch.Data)
    }
    return total
}
```

### å¹¶å‘å®‰å…¨ä¸å¿«ç…§æ–­è¨€

- MockExecutor ç°åœ¨å¯¹å†…éƒ¨æ‰¹æ¬¡å†™å…¥åŠ é”ï¼Œæ–°å¢ SnapshotExecutedBatches() ä»¥æä¾›ä¸€æ¬¡æ€§æ‹·è´å¿«ç…§ï¼Œé¿å…å¹¶å‘è¯»å†™ç«æ€ã€‚
- åœ¨å¹¶å‘æµ‹è¯•æˆ–å¼‚æ­¥æ–­è¨€ä¸­ï¼Œæ¨èä½¿ç”¨å¿«ç…§æ–¹æ³•è€Œéç›´æ¥è¯»å–å†…éƒ¨åˆ‡ç‰‡ã€‚

ç¤ºä¾‹ï¼š
```go
batch, mock := batchflow.NewBatchFlowWithMock(ctx, batchflow.PipelineConfig{
    BufferSize: 100, FlushSize: 10, FlushInterval: 50*time.Millisecond,
})

// å¹¶å‘æäº¤è‹¥å¹²è¯·æ±‚...
// ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©æ‰¹å¤„ç†åˆ·æ–°ï¼ˆæˆ–ä½¿ç”¨æ›´ç¨³å¦¥çš„åŒæ­¥æ‰‹æ®µï¼‰
time.Sleep(100 * time.Millisecond)

// ä½¿ç”¨å¿«ç…§è¿›è¡Œæ–­è¨€ï¼Œé¿å…ç«æ€
batches := mock.SnapshotExecutedBatches()
total := 0
for _, b := range batches {
    total += len(b)
}
require.GreaterOrEqual(t, total, expectedMin)
```

## ğŸ”— é›†æˆæµ‹è¯•

### å¿«é€Ÿè¿è¡Œé›†æˆæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æ•°æ®åº“é›†æˆæµ‹è¯•
make docker-all-tests

# è¿è¡Œå•ä¸ªæ•°æ®åº“æµ‹è¯•
make docker-mysql-test
make docker-postgresql-test  
make docker-sqlite-test
make docker-redis-test

# æœ¬åœ°è¿è¡Œï¼ˆéœ€è¦é¢„å…ˆå¯åŠ¨æ•°æ®åº“ï¼‰
cd test/integration
go run . -db=mysql
go run . -db=postgresql
go run . -db=sqlite
go run . -db=redis
```

### é›†æˆæµ‹è¯•é…ç½®

```bash
# ç¯å¢ƒå˜é‡é…ç½®
export TEST_DURATION=5m
export CONCURRENT_WORKERS=100
export RECORDS_PER_WORKER=20000
export BATCH_SIZE=200
export BUFFER_SIZE=5000
export PROMETHEUS_ENABLED=true
export PROMETHEUS_PORT=9090

# æ•°æ®åº“è¿æ¥é…ç½®
export MYSQL_DSN="root:password@tcp(localhost:3306)/batchflow_test"
export POSTGRES_DSN="postgres://postgres:password@localhost:5432/batchflow_test?sslmode=disable"
export SQLITE_DSN="./test.db"
export REDIS_DSN="redis://localhost:6379/0"
```

### é›†æˆæµ‹è¯•åœºæ™¯

#### 1. é«˜ååé‡æµ‹è¯•
- **ç›®æ ‡**ï¼šéªŒè¯ç³»ç»Ÿåœ¨é«˜è´Ÿè½½ä¸‹çš„ç¨³å®šæ€§
- **é…ç½®**ï¼šå¤§ç¼“å†²åŒº + ä¸­ç­‰æ‰¹æ¬¡ + å¿«é€Ÿåˆ·æ–°
- **éªŒè¯**ï¼šRPS > 100,000ï¼Œæ•°æ®å®Œæ•´æ€§ = 100%

#### 2. å¹¶å‘å·¥ä½œçº¿ç¨‹æµ‹è¯•  
- **ç›®æ ‡**ï¼šéªŒè¯å¤šçº¿ç¨‹å¹¶å‘å®‰å…¨æ€§
- **é…ç½®**ï¼š100ä¸ªå¹¶å‘å·¥ä½œçº¿ç¨‹
- **éªŒè¯**ï¼šæ— æ•°æ®ç«äº‰ï¼Œæ•°æ®å®Œæ•´æ€§ = 100%

#### 3. å¤§æ‰¹æ¬¡æµ‹è¯•
- **ç›®æ ‡**ï¼šéªŒè¯å¤§æ‰¹æ¬¡å¤„ç†èƒ½åŠ›
- **é…ç½®**ï¼šæ‰¹æ¬¡å¤§å° 5000ï¼Œç¼“å†²åŒº 50000
- **éªŒè¯**ï¼šå†…å­˜ä½¿ç”¨ç¨³å®šï¼Œæ— å†…å­˜æ³„æ¼

#### 4. å†…å­˜å‹åŠ›æµ‹è¯•
- **ç›®æ ‡**ï¼šéªŒè¯å†…å­˜ä½¿ç”¨ä¼˜åŒ–
- **é…ç½®**ï¼šå°æ‰¹æ¬¡ + å¤§æ•°æ®é‡
- **éªŒè¯**ï¼šå†…å­˜ä½¿ç”¨ < 500MB

#### 5. é•¿æ—¶é—´è¿è¡Œæµ‹è¯•
- **ç›®æ ‡**ï¼šéªŒè¯é•¿æœŸç¨³å®šæ€§
- **é…ç½®**ï¼šè¿è¡Œæ—¶é—´ > 10åˆ†é’Ÿ
- **éªŒè¯**ï¼šæ€§èƒ½æ— è¡°å‡ï¼Œæ— å†…å­˜æ³„æ¼

### Redis æµ‹è¯•æŠ¥å‘Š

#### Redis é›†æˆæµ‹è¯•ç»“æœ

| æµ‹è¯•åœºæ™¯ | é…ç½® | ç»“æœ | æ€§èƒ½æŒ‡æ ‡ |
|---------|------|------|----------|
| **é«˜ååé‡æµ‹è¯•** | BufferSize: 5000<br>BatchSize: 500<br>Workers: 1 | âœ… é€šè¿‡ | RPS: 180,000+<br>æ•°æ®å®Œæ•´æ€§: 100% |
| **å¹¶å‘å·¥ä½œçº¿ç¨‹æµ‹è¯•** | Workers: 100<br>Records: 2,000,000 | âœ… é€šè¿‡ | RPS: 250,000+<br>æ•°æ®å®Œæ•´æ€§: 100% |
| **å¤§æ‰¹æ¬¡æµ‹è¯•** | BatchSize: 5000<br>BufferSize: 50000 | âœ… é€šè¿‡ | RPS: 200,000+<br>å†…å­˜ä½¿ç”¨: < 200MB |
| **å†…å­˜å‹åŠ›æµ‹è¯•** | Records: 5,000,000<br>BatchSize: 100 | âœ… é€šè¿‡ | å†…å­˜å³°å€¼: < 300MB<br>GCæ¬¡æ•°: æ­£å¸¸ |
| **é•¿æ—¶é—´è¿è¡Œæµ‹è¯•** | Duration: 10min<br>æŒç»­è´Ÿè½½ | âœ… é€šè¿‡ | æ€§èƒ½ç¨³å®š<br>æ— å†…å­˜æ³„æ¼ |

#### Redis ç‰¹æ€§éªŒè¯

```go
func TestRedisSpecificFeatures(t *testing.T) {
    rdb := setupRedisClient(t)
    defer rdb.Close()
    
    executor := batchflow.NewRedisThrottledBatchExecutor(rdb)
    batchFlow := batchflow.NewBatchFlow(ctx, 1000, 100, 50*time.Millisecond, executor)
    defer batchFlow.Close()
    
    // æµ‹è¯•TTLè®¾ç½®
    schema := batchflow.NewSchema("redis_test",
        "cmd", "key", "value", "ex_flag", "ttl")
    
    request := batchflow.NewRequest(schema).
        SetString("cmd", "SET").
        SetString("key", "test:ttl").
        SetString("value", "test_value").
        SetString("ex_flag", "EX").
        SetInt64("ttl", 60) // 60ç§’TTL
    
    err := batchFlow.Submit(ctx, request)
    assert.NoError(t, err)
    
    // ç­‰å¾…å¤„ç†å®Œæˆ
    time.Sleep(100 * time.Millisecond)
    
    // éªŒè¯keyå­˜åœ¨ä¸”æœ‰TTL
    exists := rdb.Exists(ctx, "test:ttl").Val()
    assert.Equal(t, int64(1), exists)
    
    ttl := rdb.TTL(ctx, "test:ttl").Val()
    assert.True(t, ttl > 0 && ttl <= 60*time.Second)
}
```

#### Redis æ€§èƒ½åŸºå‡†

```go
func BenchmarkRedisBatchInsert(b *testing.B) {
    rdb := setupRedisClient(b)
    defer rdb.Close()
    
    executor := batchflow.NewRedisThrottledBatchExecutor(rdb)
    batchFlow := batchflow.NewBatchFlow(ctx, 5000, 500, 50*time.Millisecond, executor)
    defer batchFlow.Close()
    
    schema := batchflow.NewSchema("benchmark",
        "cmd", "key", "value")
    
    b.ResetTimer()
    
    for i := 0; i < b.N; i++ {
        request := batchflow.NewRequest(schema).
            SetString("cmd", "SET").
            SetString("key", fmt.Sprintf("bench:%d", i)).
            SetString("value", fmt.Sprintf("value_%d", i))
        
        batchFlow.Submit(ctx, request)
    }
}
```

## ğŸ“Š æ€§èƒ½æµ‹è¯•

### åŸºå‡†æµ‹è¯•

```bash
# è¿è¡ŒåŸºå‡†æµ‹è¯•
go test -bench=. -benchmem ./...

# è¿è¡Œç‰¹å®šåŸºå‡†æµ‹è¯•
go test -bench=BenchmarkBatchInsert -benchmem

# ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š
go test -bench=. -cpuprofile=cpu.prof -memprofile=mem.prof
go tool pprof cpu.prof
go tool pprof mem.prof
```

### å‹åŠ›æµ‹è¯•

```go
func TestStressTest(t *testing.T) {
    if testing.Short() {
        t.Skip("è·³è¿‡å‹åŠ›æµ‹è¯•")
    }
    
    db := setupTestDB(t, "mysql")
    defer db.Close()
    
    executor := batchflow.NewSQLThrottledBatchExecutorWithDriver(db, batchflow.DefaultMySQLDriver)
    batchFlow := batchflow.NewBatchFlow(ctx, 10000, 500, 50*time.Millisecond, executor)
    defer batchFlow.Close()
    
    schema := batchflow.NewSQLSchema("stress_test", batchflow.ConflictIgnoreOperationConfig, "id", "data")
    
    const totalRecords = 1000000
    startTime := time.Now()
    
    for i := 0; i < totalRecords; i++ {
        request := batchflow.NewRequest(schema).
            SetInt64("id", int64(i)).
            SetString("data", strings.Repeat("x", 100)) // 100å­—èŠ‚æ•°æ®
        
        err := batchFlow.Submit(ctx, request)
        assert.NoError(t, err)
    }
    
    duration := time.Since(startTime)
    rps := float64(totalRecords) / duration.Seconds()
    
    t.Logf("å‹åŠ›æµ‹è¯•å®Œæˆ: %d è®°å½•, è€—æ—¶: %v, RPS: %.0f", totalRecords, duration, rps)
    
    // éªŒè¯æ€§èƒ½è¦æ±‚
    assert.True(t, rps > 50000, "RPSåº”è¯¥å¤§äº50,000")
}
```

## ğŸ“ˆ ç›‘æ§æµ‹è¯•

### Prometheus æŒ‡æ ‡éªŒè¯

```go
func TestPrometheusMetrics(t *testing.T) {
    prometheusMetrics := NewPrometheusMetrics()
    err := prometheusMetrics.StartServer(9091)
    assert.NoError(t, err)
    defer prometheusMetrics.StopServer()
    
    // åˆ›å»ºå¸¦ç›‘æ§çš„æ‰§è¡Œå™¨
    executor := batchflow.NewSQLThrottledBatchExecutorWithDriver(db, batchflow.DefaultMySQLDriver)
    metricsReporter := NewPrometheusMetricsReporter(prometheusMetrics, "mysql", "test")
    executor = executor.WithMetricsReporter(metricsReporter).(*batchflow.ThrottledBatchExecutor)
    
    batchFlow := batchflow.NewBatchFlow(ctx, 1000, 100, 100*time.Millisecond, executor)
    defer batchFlow.Close()
    
    // æ‰§è¡Œä¸€äº›æ“ä½œ
    schema := batchflow.NewSQLSchema("metrics_test", batchflow.ConflictIgnoreOperationConfig, "id", "data")
    for i := 0; i < 500; i++ {
        request := batchflow.NewRequest(schema).
            SetInt64("id", int64(i)).
            SetString("data", fmt.Sprintf("data_%d", i))
        
        batchFlow.Submit(ctx, request)
    }
    
    // ç­‰å¾…æŒ‡æ ‡æ›´æ–°
    time.Sleep(200 * time.Millisecond)
    
    // éªŒè¯æŒ‡æ ‡ç«¯ç‚¹
    resp, err := http.Get("http://localhost:9091/metrics")
    assert.NoError(t, err)
    defer resp.Body.Close()
    
    body, err := io.ReadAll(resp.Body)
    assert.NoError(t, err)
    
    metrics := string(body)
    assert.Contains(t, metrics, "batchflow_records_processed_total")
    assert.Contains(t, metrics, "batchflow_records_rate_total")
    assert.Contains(t, metrics, "batchflow_data_integrity_rate")
    assert.Contains(t, metrics, "batchflow_current_rps")
}
```

### Grafana é¢æ¿æµ‹è¯•

```bash
# å¯åŠ¨å®Œæ•´ç›‘æ§æ ˆ
docker-compose -f docker-compose.integration.yml up -d

# è¿è¡Œé›†æˆæµ‹è¯•ç”Ÿæˆæ•°æ®
cd test/integration && go run .

# éªŒè¯Grafanaé¢æ¿
curl -u admin:admin http://localhost:3000/api/dashboards/uid/batchflow-performance

# æ£€æŸ¥æ•°æ®æºè¿æ¥
curl -u admin:admin http://localhost:3000/api/datasources/proxy/1/api/v1/query?query=up
```

## ğŸ”§ æµ‹è¯•å·¥å…·å’Œè¾…åŠ©å‡½æ•°

### æµ‹è¯•æ•°æ®åº“è®¾ç½®

```go
func setupTestDB(t *testing.T, dbType string) *sql.DB {
    var dsn string
    var driver string
    
    switch dbType {
    case "mysql":
        driver = "mysql"
        dsn = os.Getenv("MYSQL_TEST_DSN")
        if dsn == "" {
            dsn = "root:password@tcp(localhost:3306)/batchflow_test"
        }
    case "postgres":
        driver = "postgres"
        dsn = os.Getenv("POSTGRES_TEST_DSN")
        if dsn == "" {
            dsn = "postgres://postgres:password@localhost:5432/batchflow_test?sslmode=disable"
        }
    case "sqlite":
        driver = "sqlite3"
        dsn = ":memory:"
    }
    
    db, err := sql.Open(driver, dsn)
    require.NoError(t, err)
    
    err = db.Ping()
    require.NoError(t, err)
    
    // åˆ›å»ºæµ‹è¯•è¡¨
    createTestTables(t, db, dbType)
    
    return db
}

func createTestTables(t *testing.T, db *sql.DB, dbType string) {
    var createSQL string
    
    switch dbType {
    case "mysql":
        createSQL = `
        CREATE TABLE IF NOT EXISTS test_users (
            id BIGINT PRIMARY KEY,
            name VARCHAR(255) NOT NULL,
            email VARCHAR(255) NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )`
    case "postgres":
        createSQL = `
        CREATE TABLE IF NOT EXISTS test_users (
            id BIGINT PRIMARY KEY,
            name VARCHAR(255) NOT NULL,
            email VARCHAR(255) NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )`
    case "sqlite":
        createSQL = `
        CREATE TABLE IF NOT EXISTS test_users (
            id INTEGER PRIMARY KEY,
            name TEXT NOT NULL,
            email TEXT NOT NULL,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )`
    }
    
    _, err := db.Exec(createSQL)
    require.NoError(t, err)
}
```

### æ€§èƒ½æ–­è¨€å·¥å…·

```go
type PerformanceAssertion struct {
    t         *testing.T
    startTime time.Time
    records   int64
}

func NewPerformanceAssertion(t *testing.T) *PerformanceAssertion {
    return &PerformanceAssertion{
        t:         t,
        startTime: time.Now(),
    }
}

func (pa *PerformanceAssertion) RecordProcessed(count int64) {
    pa.records += count
}

func (pa *PerformanceAssertion) AssertMinRPS(minRPS float64) {
    duration := time.Since(pa.startTime)
    actualRPS := float64(pa.records) / duration.Seconds()
    
    assert.True(pa.t, actualRPS >= minRPS, 
        "RPS too low: expected >= %.0f, got %.0f", minRPS, actualRPS)
}

func (pa *PerformanceAssertion) AssertMaxDuration(maxDuration time.Duration) {
    duration := time.Since(pa.startTime)
    assert.True(pa.t, duration <= maxDuration,
        "Duration too long: expected <= %v, got %v", maxDuration, duration)
}
```

## ğŸš€ CI/CD é›†æˆ

### GitHub Actions é…ç½®

```yaml
# .github/workflows/test.yml
name: Tests

on: [push, pull_request]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-go@v3
        with:
          go-version: '1.21'
      
      - name: Run unit tests
        run: |
          go test -v -race -coverprofile=coverage.out ./...
          go tool cover -html=coverage.out -o coverage.html
      
      - name: Upload coverage
        uses: actions/upload-artifact@v3
        with:
          name: coverage-report
          path: coverage.html

  integration-tests:
    runs-on: ubuntu-latest
    services:
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: password
          MYSQL_DATABASE: batchflow_test
        ports:
          - 3306:3306
      
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: password
          POSTGRES_DB: batchflow_test
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        ports:
          - 6379:6379
    
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-go@v3
        with:
          go-version: '1.21'
      
      - name: Run integration tests
        run: |
          cd test/integration
          go run . -db=mysql
          go run . -db=postgresql  
          go run . -db=redis
```

### æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ

```bash
# ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
go test -v -json ./... > test-results.json

# è½¬æ¢ä¸ºHTMLæŠ¥å‘Š
go-junit-report < test-results.json > test-results.xml

# ç”Ÿæˆè¦†ç›–ç‡å¾½ç« 
gocov convert coverage.out | gocov-xml > coverage.xml
```

## ğŸ”§ RPS æŒ‡æ ‡ä¿®å¤è¯´æ˜

### é—®é¢˜æè¿°
åŸæ¥çš„ `batchflow_records_per_second` æŒ‡æ ‡ä½¿ç”¨äº†é”™è¯¯çš„ Histogram ç±»å‹ï¼Œå¯¼è‡´ï¼š
- `batchflow_records_per_second_bucket` æŸ¥è¯¢ç»“æœéƒ½æ˜¯1
- `rate(batchflow_records_per_second_bucket[5m])` æŸ¥è¯¢ç»“æœéƒ½æ˜¯0

### ä¿®å¤æ–¹æ¡ˆ
1. **åˆ é™¤æœ‰é—®é¢˜çš„ Histogram**ï¼šç§»é™¤äº† `recordsPerSecond` å­—æ®µ
2. **æ–°å¢ä¸“ç”¨ RPS Counter**ï¼š`batchflow_records_rate_total` ç”¨äº `rate()` è®¡ç®—
3. **ä¿ç•™ç¬æ—¶ RPS Gauge**ï¼š`batchflow_current_rps` æ˜¾ç¤ºå½“å‰å€¼

### æ­£ç¡®çš„ RPS æŸ¥è¯¢æ–¹æ³•

```promql
# å½“å‰ RPSï¼ˆç¬æ—¶å€¼ï¼‰
batchflow_current_rps

# å¹³å‡ RPSï¼ˆè¿‡å»5åˆ†é’Ÿï¼Œæ¨èï¼‰
rate(batchflow_records_rate_total[5m])

# å³°å€¼ RPSï¼ˆè¿‡å»1å°æ—¶ï¼‰
max_over_time(batchflow_current_rps[1h])
```

### å“åº”æ—¶é—´æŒ‡æ ‡ä¿®å¤

#### é—®é¢˜æè¿°
Grafana é¢æ¿ä¸­æŸ¥è¯¢çš„åˆ†ä½æ•°ä¸ Prometheus é…ç½®ä¸åŒ¹é…ï¼š
- é¢æ¿æŸ¥è¯¢ï¼š`quantile="0.95"`
- å®é™…é…ç½®ï¼šåªæœ‰ `0.5`, `0.9`, `0.99` åˆ†ä½æ•°

#### ä¿®å¤æ–¹æ¡ˆ
æ›´æ–° Grafana é¢æ¿æŸ¥è¯¢ï¼Œä½¿ç”¨å®é™…å¯ç”¨çš„åˆ†ä½æ•°ï¼š

```promql
# å¯ç”¨çš„å“åº”æ—¶é—´åˆ†ä½æ•°æŸ¥è¯¢
batchflow_response_time_seconds{quantile="0.99"}  # 99th percentile
batchflow_response_time_seconds{quantile="0.9"}   # 90th percentile  
batchflow_response_time_seconds{quantile="0.5"}   # 50th percentile (median)
```

### æµ‹è¯•éªŒè¯

```go
// éªŒè¯ä¿®å¤åçš„æŒ‡æ ‡å­˜åœ¨
assert.Contains(t, metrics, "batchflow_records_rate_total")
assert.Contains(t, metrics, "batchflow_current_rps")
assert.Contains(t, metrics, "batchflow_tests_run_total")
assert.Contains(t, metrics, "batchflow_records_processed_total")

// éªŒè¯å“åº”æ—¶é—´åˆ†ä½æ•°æŒ‡æ ‡
assert.Contains(t, metrics, "batchflow_response_time_seconds")

// éªŒè¯æµ‹è¯•ç»“æœç»Ÿè®¡æŒ‡æ ‡ï¼ˆä¿®å¤åç›´æ¥æ˜¾ç¤ºç´¯è®¡å€¼ï¼‰
assert.Contains(t, metrics, "batchflow_tests_run_total{result=\"success\"}")
assert.Contains(t, metrics, "batchflow_tests_run_total{result=\"failure\"}")

// éªŒè¯å†…å­˜ä½¿ç”¨æŒ‡æ ‡ï¼ˆå·²ç»æ˜¯ MB å•ä½ï¼Œæ— éœ€è½¬æ¢ï¼‰
assert.Contains(t, metrics, "batchflow_memory_usage_mb{type=\"alloc\"}")
assert.Contains(t, metrics, "batchflow_memory_usage_mb{type=\"sys\"}")

// éªŒè¯æ­£ç¡®çš„æŸ¥è¯¢æ–¹æ³•
// RPS è®¡ç®—ï¼šrate(batchflow_records_rate_total[5m])
// å¤„ç†è®°å½•æ•°ï¼šbatchflow_records_processed_total{status="processed"}
// å“åº”æ—¶é—´ï¼šbatchflow_response_time_seconds{quantile="0.99|0.9|0.5"}
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [API_REFERENCE.md](API_REFERENCE.md) - APIè¯¦ç»†å‚è€ƒ
- [EXAMPLES.md](EXAMPLES.md) - ä½¿ç”¨ç¤ºä¾‹
- [MONITORING_GUIDE.md](MONITORING_GUIDE.md) - ç›‘æ§é…ç½®
- [TROUBLESHOOTING.md](TROUBLESHOOTING.md) - é—®é¢˜æ’æŸ¥

---

ğŸ’¡ **æµ‹è¯•æœ€ä½³å®è·µ**ï¼š
1. å•å…ƒæµ‹è¯•è¦†ç›–ç‡ä¿æŒåœ¨80%ä»¥ä¸Š
2. é›†æˆæµ‹è¯•éªŒè¯æ‰€æœ‰æ•°æ®åº“é©±åŠ¨
3. ä½¿ç”¨æ­£ç¡®çš„æŒ‡æ ‡ç±»å‹è¿›è¡Œç›‘æ§æµ‹è¯•
4. å®šæœŸéªŒè¯ Prometheus æŸ¥è¯¢çš„å‡†ç¡®æ€§
3. æ€§èƒ½æµ‹è¯•å»ºç«‹åŸºå‡†çº¿å’Œå›å½’æ£€æµ‹
4. ç›‘æ§æµ‹è¯•ç¡®ä¿æŒ‡æ ‡å‡†ç¡®æ€§