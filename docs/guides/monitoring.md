# BatchFlow ç›‘æ§ç³»ç»ŸæŒ‡å—

## ğŸ“Š ç›‘æ§ç³»ç»Ÿæ¦‚è§ˆ

BatchFlow æä¾›å®Œæ•´çš„ç›‘æ§è§£å†³æ–¹æ¡ˆï¼ŒåŸºäº Prometheus + Grafana æŠ€æœ¯æ ˆï¼Œå®ç°å®æ—¶æ€§èƒ½ç›‘æ§ã€æ•°æ®å®Œæ•´æ€§éªŒè¯å’Œç³»ç»Ÿå¥åº·æ£€æŸ¥ã€‚

### ğŸ—ï¸ ç›‘æ§æ¶æ„

```
BatchFlow Application
        â†“ (metrics)
   Prometheus Server  
        â†“ (query)
    Grafana Dashboard
        â†“ (alerts)
   Alert Manager
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨ç›‘æ§æ ˆ

```bash
# ä½¿ç”¨ Docker Compose å¯åŠ¨å®Œæ•´ç›‘æ§ç¯å¢ƒ
docker-compose -f docker-compose.integration.yml up -d

# éªŒè¯æœåŠ¡çŠ¶æ€
docker-compose ps

# è®¿é—®æœåŠ¡
# Grafana: http://localhost:3000 (admin/admin)
# Prometheus: http://localhost:9090
```

### 2. é…ç½®åº”ç”¨ç›‘æ§

```go
package main

import (
    "github.com/rushairer/batchflow"
    "github.com/rushairer/batchflow/drivers/mysql"
    "github.com/rushairer/batchflow/test/integration"
)

func main() {
    // 1. åˆ›å»º Prometheus æŒ‡æ ‡æ”¶é›†å™¨
    prometheusMetrics := integration.NewPrometheusMetrics()
    
    // 2. å¯åŠ¨æŒ‡æ ‡æœåŠ¡å™¨
    go prometheusMetrics.StartServer(9090)
    defer prometheusMetrics.StopServer()
    
    // 3. åˆ›å»ºå¸¦ç›‘æ§çš„æ‰§è¡Œå™¨
    executor := batchflow.NewSQLThrottledBatchExecutorWithDriver(db, batchflow.DefaultMySQLDriver)
    metricsReporter := integration.NewPrometheusMetricsReporter(
        prometheusMetrics, "mysql", "production")
    executor = executor.WithMetricsReporter(metricsReporter)
    
    // 4. åˆ›å»º BatchFlow å®ä¾‹
    batchFlow := batchflow.NewBatchFlow(ctx, 5000, 200, 100*time.Millisecond, executor)
    defer batchFlow.Close()
    
    // 5. æ­£å¸¸ä½¿ç”¨ï¼ŒæŒ‡æ ‡è‡ªåŠ¨æ”¶é›†
    // ...
}
```

## ğŸ“ˆ æ ¸å¿ƒæŒ‡æ ‡

### æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡åç§° | ç±»å‹ | æè¿° | æ ‡ç­¾ | æŸ¥è¯¢ç¤ºä¾‹ |
|---------|------|------|------|----------|
| `batchflow_records_processed_total` | Counter | å·²å¤„ç†è®°å½•æ€»æ•°ï¼ˆæŒ‰çŠ¶æ€åˆ†ç±»ï¼‰ | `database`, `test_name`, `status` | `sum(batchflow_records_processed_total)` |
| `batchflow_records_rate_total` | Counter | ç”¨äº RPS è®¡ç®—çš„ç´¯è®¡è®°å½•æ•° | `database`, `test_name` | `rate(batchflow_records_rate_total[5m])` |
| `batchflow_current_rps` | Gauge | å½“å‰æ¯ç§’å¤„ç†è®°å½•æ•°ï¼ˆç¬æ—¶å€¼ï¼‰ | `database`, `test_name` | `batchflow_current_rps` |
| `batchflow_batch_execution_duration_ms` | Histogram | æ‰¹æ¬¡æ‰§è¡Œè€—æ—¶åˆ†å¸ƒ | `database`, `table`, `test_name` | `histogram_quantile(0.95, rate(batchflow_batch_execution_duration_ms_bucket[5m]))` |
| `batchflow_batch_size` | Histogram | æ‰¹æ¬¡å¤§å°åˆ†å¸ƒ | `database`, `table`, `test_name` | `histogram_quantile(0.50, rate(batchflow_batch_size_bucket[5m]))` |

### è´¨é‡æŒ‡æ ‡

| æŒ‡æ ‡åç§° | ç±»å‹ | æè¿° | æ ‡ç­¾ |
|---------|------|------|------|
| `batchflow_data_integrity_rate` | Gauge | æ•°æ®å®Œæ•´æ€§ç‡ (0-1) | `database`, `test_name` |
| `batchflow_error_rate` | Gauge | é”™è¯¯ç‡ (0-1) | `database`, `test_name` |
| `batchflow_batch_success_total` | Counter | æˆåŠŸæ‰¹æ¬¡æ€»æ•° | `database`, `table`, `test_name` |
| `batchflow_batch_failed_total` | Counter | å¤±è´¥æ‰¹æ¬¡æ€»æ•° | `database`, `table`, `test_name` |

### ç³»ç»ŸæŒ‡æ ‡

| æŒ‡æ ‡åç§° | ç±»å‹ | æè¿° | æ ‡ç­¾ |
|---------|------|------|------|
| `batchflow_memory_usage_bytes` | Gauge | å†…å­˜ä½¿ç”¨é‡ | `database`, `test_name` |
| `batchflow_active_connections` | Gauge | æ´»è·ƒè¿æ¥æ•° | `database` |
| `batchflow_buffer_utilization` | Gauge | ç¼“å†²åŒºåˆ©ç”¨ç‡ (0-1) | `database`, `test_name` |

## ğŸ” Retry æŒ‡æ ‡ä¸æŸ¥è¯¢ç¤ºä¾‹

### æŒ‡æ ‡è¯­ä¹‰
- å¯é‡è¯•é”™è¯¯ï¼ˆretry:*ï¼‰ï¼šå½“æ‰§è¡Œå™¨å°†é”™è¯¯åˆ†ç±»ä¸ºå¯é‡è¯•æ—¶è®¡æ•°é€’å¢ï¼ˆæ¯æ¬¡é‡è¯•å‰ä¸€æ¬¡ï¼‰
- æœ€ç»ˆå¤±è´¥ï¼ˆfinal:*ï¼‰ï¼šè¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°æˆ–è¢«åˆ¤å®šä¸ºä¸å¯é‡è¯•æ—¶è®¡æ•°é€’å¢ä¸€æ¬¡
- æ‰§è¡Œè€—æ—¶ï¼šæ‰¹æ¬¡æ‰§è¡Œè€—æ—¶ç›´æ–¹å›¾åŒ…å«æ‰€æœ‰å°è¯•ä¸é€€é¿æ—¶é—´ï¼ˆstatus=success/failï¼‰

å¸¸è§åŸå› æ ‡ç­¾ï¼ˆreasonï¼‰
- deadlockã€lock_timeoutã€timeoutã€connectionã€ioã€contextã€non_retryable

### PromQL ç¤ºä¾‹
```promql
# é‡è¯•é€Ÿç‡ï¼ˆæŒ‰è¡¨å’ŒåŸå› ï¼‰
sum(rate(batchflow_errors_total{type=~"retry:.*"}[5m])) by (table, type)

# æœ€ç»ˆå¤±è´¥é€Ÿç‡ï¼ˆæŒ‰è¡¨å’ŒåŸå› ï¼‰
sum(rate(batchflow_errors_total{type=~"final:.*"}[5m])) by (table, type)

# é‡è¯•å æ¯”ï¼ˆè¿‘5åˆ†é’Ÿçª—å£ï¼‰
sum(rate(batchflow_errors_total{type=~"retry:.*"}[5m]))
/
sum(rate(batchflow_errors_total{type=~"(retry:|final:).*"}[5m]))

# 95åˆ†ä½æ‰§è¡Œè€—æ—¶ï¼ˆå«é‡è¯•ä¸é€€é¿ï¼‰
histogram_quantile(0.95, rate(batchflow_batch_execution_duration_ms_bucket[5m]))
```

### å¯è§†åŒ–å»ºè®®
- timeseriesï¼šretry:* ä¸ final:* åˆ†åˆ«æ›²çº¿ï¼ŒæŒ‰ table/type åˆ†ç»„
- statï¼šè¿‘5åˆ†é’Ÿæœ€ç»ˆå¤±è´¥ç‡
- timeseriesï¼šP95 æ‰§è¡Œè€—æ—¶ï¼Œç»“åˆé˜Ÿåˆ—/å¹¶å‘å˜åŒ–è§‚å¯Ÿé€€é¿å½±å“

## ğŸš€ å¼€ç®±å³ç”¨ Prometheusï¼ˆç¤ºä¾‹ï¼‰
- ç¤ºä¾‹ä»£ç ï¼šexamples/metrics/prometheus
- æä¾›ï¼š
  - æŒ‡æ ‡æ³¨å†Œä¸ HTTP /metrics æœåŠ¡ï¼ˆprometheus_metrics.goï¼‰
  - æ‰§è¡Œå™¨/BatchFlow å¯¹æ¥çš„ Reporterï¼ˆprometheus_reporter.goï¼‰
  - å•ä¸€ Grafana Dashboardï¼ˆtest/integration/grafana/provisioning/dashboards/batchflow-performance.jsonï¼‰
- é€‚ç”¨åœºæ™¯ï¼šå¸Œæœ›â€œå¿«é€Ÿå¯è§†åŒ– + æŒ‰éœ€è£å‰ªâ€çš„å›¢é˜Ÿ
- ä½¿ç”¨æ­¥éª¤ï¼š
  1) NewMetrics + StartServer(2112)
  2) NewReporter(metrics, database, testName)
  3) executor.WithMetricsReporter(reporter) å¹¶ä¼ å…¥ NewBatchFlow
  4) å¯¼å…¥ä¸Šè¿° Dashboard

æç¤ºï¼šç”Ÿäº§ä¸­å»ºè®®æŒ‰éœ€é…ç½® Namespace/ConstLabels/Bucketsï¼Œå¹¶è°¨æ…å¼€å¯ table ç»´åº¦ï¼Œé¿å…æ ‡ç­¾åŸºæ•°è†¨èƒ€ã€‚

## ğŸ“Š Grafana æŒ‡æ ‡ä¿®å¤è¯´æ˜

### å·²ä¿®å¤çš„æŒ‡æ ‡é—®é¢˜

#### 1. æµ‹è¯•ç»“æœç»Ÿè®¡æŒ‡æ ‡ä¿®å¤
**é—®é¢˜**ï¼š`increase(batchflow_tests_run_total{result="success"}[5m])` æŸ¥è¯¢æ— æ•°æ®  
**ä¿®å¤**ï¼šæ”¹ä¸ºç›´æ¥æŸ¥è¯¢ç´¯è®¡å€¼ `batchflow_tests_run_total{result="success"}`  
**åŸå› **ï¼šé¿å…æ—¶é—´çª—å£å’Œé‡‡é›†é¢‘ç‡å¯¼è‡´çš„ `increase()` è®¡ç®—é—®é¢˜

#### 2. æ•°æ®åº“ååé‡ç»Ÿè®¡ä¿®å¤
**é—®é¢˜**ï¼š`sum by (database) (increase(batchflow_records_rate_total[5m]))` æŸ¥è¯¢ä¸å‡†ç¡®  
**ä¿®å¤**ï¼šæ”¹ä¸º `sum by (database) (batchflow_records_processed_total{status="processed"})`  
**åŸå› **ï¼šä½¿ç”¨ä¸“é—¨ç”¨äºç»Ÿè®¡å¤„ç†è®°å½•æ•°çš„æŒ‡æ ‡ï¼Œè€Œéç”¨äº RPS è®¡ç®—çš„ Counter

#### 3. å†…å­˜ä½¿ç”¨æŒ‡æ ‡ä¿®å¤
**é—®é¢˜**ï¼š`batchflow_memory_usage_mb * 1024 * 1024` å•ä½è½¬æ¢é”™è¯¯  
**ä¿®å¤**ï¼šç›´æ¥ä½¿ç”¨ `batchflow_memory_usage_mb`  
**åŸå› **ï¼šæŒ‡æ ‡å·²ç»æ˜¯ MB å•ä½ï¼Œæ— éœ€å†æ¬¡è½¬æ¢

#### 4. RPS æŒ‡æ ‡ä¿®å¤ï¼ˆä¹‹å‰å·²ä¿®å¤ï¼‰
**é—®é¢˜**ï¼š`batchflow_records_per_second_bucket` ä½¿ç”¨äº†é”™è¯¯çš„ Histogram ç±»å‹  
**ä¿®å¤**ï¼šä½¿ç”¨ `rate(batchflow_records_rate_total[5m])` è®¡ç®—å¹³å‡ RPS  
**åŸå› **ï¼šCounter + rate() æ˜¯è®¡ç®—é€Ÿç‡çš„æ­£ç¡®æ–¹å¼

#### 5. å“åº”æ—¶é—´åˆ†ä½æ•°ä¿®å¤ï¼ˆä¹‹å‰å·²ä¿®å¤ï¼‰
**é—®é¢˜**ï¼šæŸ¥è¯¢ `quantile="0.95"` ä½†é…ç½®ä¸­åªæœ‰ 0.5, 0.9, 0.99  
**ä¿®å¤**ï¼šä½¿ç”¨å®é™…å¯ç”¨çš„åˆ†ä½æ•° `quantile="0.99"`  
**åŸå› **ï¼šç¡®ä¿æŸ¥è¯¢ä¸ Summary æŒ‡æ ‡é…ç½®åŒ¹é…

#### 6. æµ‹è¯•åç§°æ ‡ç­¾ä¸åŒ¹é…ä¿®å¤
**é—®é¢˜**ï¼š`batchflow_current_rps` ç­‰æŒ‡æ ‡ä¸­è‹±æ–‡æµ‹è¯•åç§°ï¼ˆå¦‚ `batch_insert`ï¼‰æ²¡æœ‰æ•°æ®  
**ä¿®å¤**ï¼šå°†åˆå§‹åŒ–çš„æµ‹è¯•ç±»å‹æ”¹ä¸ºå®é™…ä½¿ç”¨çš„ä¸­æ–‡åç§°  
**åŸå› **ï¼šåˆå§‹åŒ–ä½¿ç”¨è‹±æ–‡åç§°ï¼Œä½†å®é™…æµ‹è¯•ä½¿ç”¨ä¸­æ–‡åç§°ï¼Œå¯¼è‡´æ ‡ç­¾ä¸åŒ¹é…

**å®é™…çš„æµ‹è¯•åç§°**ï¼š
- `"é«˜ååé‡æµ‹è¯•"` (åŸ `batch_insert`)
- `"å¹¶å‘å·¥ä½œçº¿ç¨‹æµ‹è¯•"` (åŸ `concurrent_workers`) 
- `"å¤§æ‰¹æ¬¡æµ‹è¯•"` (åŸ `large_batch`)
- `"å†…å­˜å‹åŠ›æµ‹è¯•"` (åŸ `stress_test`)
- `"é•¿æ—¶é—´è¿è¡Œæµ‹è¯•"` (æ–°å¢)

### æ­£ç¡®çš„æŸ¥è¯¢æ–¹æ³•

```promql
# âœ… æ­£ç¡®çš„ RPS æŸ¥è¯¢
rate(batchflow_records_rate_total[5m])           # å¹³å‡ RPS
batchflow_current_rps                            # ç¬æ—¶ RPS

# âœ… æ­£ç¡®çš„å¤„ç†è®°å½•æ•°æŸ¥è¯¢
sum by (database) (batchflow_records_processed_total{status="processed"})

# âœ… æ­£ç¡®çš„æµ‹è¯•ç»“æœç»Ÿè®¡
batchflow_tests_run_total{result="success"}     # æˆåŠŸæµ‹è¯•æ€»æ•°
batchflow_tests_run_total{result="failure"}     # å¤±è´¥æµ‹è¯•æ€»æ•°

# âœ… æ­£ç¡®çš„å†…å­˜ä½¿ç”¨æŸ¥è¯¢
batchflow_memory_usage_mb{type="alloc"}         # å½“å‰åˆ†é…å†…å­˜ (MB)
batchflow_memory_usage_mb{type="sys"}           # ç³»ç»Ÿå†…å­˜ (MB)

# âœ… æ­£ç¡®çš„å“åº”æ—¶é—´åˆ†ä½æ•°
batchflow_response_time_seconds{quantile="0.99"} # 99th percentile
batchflow_response_time_seconds{quantile="0.9"}  # 90th percentile
batchflow_response_time_seconds{quantile="0.5"}  # 50th percentile (median)
```

## ğŸ›ï¸ Grafana é¢æ¿é…ç½®

### Retry æŒ‡æ ‡ä»ªè¡¨æ¿ï¼ˆå¯ç›´æ¥å¯¼å…¥ï¼‰

å°†ä»¥ä¸‹ JSON ä¿å­˜ä¸º dashboards/batchflow-retry.json å¹¶åœ¨ Grafana ä¸­å¯¼å…¥ã€‚è¯¥é¢æ¿åŒ…å«ï¼š
- é‡è¯•é€Ÿç‡ï¼ˆretry:*ï¼‰ä¸æœ€ç»ˆå¤±è´¥é€Ÿç‡ï¼ˆfinal:*ï¼‰
- è¿‘ 5 åˆ†é’Ÿé‡è¯•å æ¯”ï¼ˆretry / (retry+final)ï¼‰
- P95 æ‰§è¡Œè€—æ—¶ï¼ˆå«é‡è¯•ä¸é€€é¿ï¼‰
- å¯é€‰å˜é‡ï¼šdatabase ä¸ table

```json
{
  "title": "BatchFlow Retry ä¸æ‰§è¡Œè€—æ—¶",
  "timezone": "browser",
  "editable": true,
  "schemaVersion": 36,
  "version": 1,
  "refresh": "10s",
  "tags": ["batchflow", "retry"],
  "time": { "from": "now-1h", "to": "now" },
  "templating": {
    "list": [
      {
        "name": "database",
        "label": "Database",
        "type": "query",
        "datasource": null,
        "query": "label_values(batchflow_errors_total, database)",
        "refresh": 2,
        "includeAll": true,
        "multi": true
      },
      {
        "name": "table",
        "label": "Table",
        "type": "query",
        "datasource": null,
        "query": "label_values(batchflow_errors_total, table)",
        "refresh": 2,
        "includeAll": true,
        "multi": true
      }
    ]
  },
  "panels": [
    {
      "type": "timeseries",
      "title": "é‡è¯•é€Ÿç‡ï¼ˆretry:*ï¼‰",
      "gridPos": {"x": 0, "y": 0, "w": 12, "h": 8},
      "targets": [
        {
          "expr": "sum(rate(batchflow_errors_total{type=~\"retry:.*\",database=~\"$database\",table=~\"$table\"}[5m])) by (table, type)",
          "legendFormat": "{{table}} {{type}}"
        }
      ]
    },
    {
      "type": "timeseries",
      "title": "æœ€ç»ˆå¤±è´¥é€Ÿç‡ï¼ˆfinal:*ï¼‰",
      "gridPos": {"x": 12, "y": 0, "w": 12, "h": 8},
      "targets": [
        {
          "expr": "sum(rate(batchflow_errors_total{type=~\"final:.*\",database=~\"$database\",table=~\"$table\"}[5m])) by (table, type)",
          "legendFormat": "{{table}} {{type}}"
        }
      ]
    },
    {
      "type": "stat",
      "title": "é‡è¯•å æ¯”ï¼ˆè¿‘5mï¼‰",
      "gridPos": {"x": 0, "y": 8, "w": 6, "h": 6},
      "targets": [
        {
          "expr": "sum(rate(batchflow_errors_total{type=~\"retry:.*\",database=~\"$database\",table=~\"$table\"}[5m])) / sum(rate(batchflow_errors_total{type=~\"(retry:|final:).*\",database=~\"$database\",table=~\"$table\"}[5m]))",
          "legendFormat": "retry_ratio"
        }
      ],
      "options": {
        "reduceOptions": {"calcs": ["lastNotNull"]},
        "orientation": "horizontal",
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto"
      },
      "fieldConfig": {
        "defaults": {
          "unit": "percentunit",
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {"color": "green", "value": 0},
              {"color": "yellow", "value": 0.2},
              {"color": "red", "value": 0.5}
            ]
          }
        }
      }
    },
    {
      "type": "timeseries",
      "title": "P95 æ‰§è¡Œè€—æ—¶ï¼ˆå«é‡è¯•ä¸é€€é¿ï¼‰",
      "gridPos": {"x": 6, "y": 8, "w": 18, "h": 6},
      "targets": [
        {
          "expr": "histogram_quantile(0.95, rate(batchflow_batch_execution_duration_ms_bucket{database=~\"$database\"}[5m]))",
          "legendFormat": "P95 {{database}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "ms"
        }
      }
    }
  ]
}
```

å¯¼å…¥æ–¹å¼
```bash
curl -X POST \
  http://admin:admin@localhost:3000/api/dashboards/db \
  -H 'Content-Type: application/json' \
  -d @dashboards/batchflow-retry.json
```

### ä¸»è¦é¢æ¿

#### 1. æ€§èƒ½æ¦‚è§ˆé¢æ¿

```json
{
  "title": "BatchFlow æ€§èƒ½æ¦‚è§ˆ",
  "panels": [
    {
      "title": "å½“å‰ RPSï¼ˆç¬æ—¶å€¼ï¼‰",
      "type": "stat",
      "targets": [
        {
          "expr": "sum(batchflow_current_rps) by (database)",
          "legendFormat": "{{database}}"
        }
      ]
    },
    {
      "title": "å¹³å‡ RPSï¼ˆ5åˆ†é’Ÿï¼‰",
      "type": "stat",
      "targets": [
        {
          "expr": "sum(rate(batchflow_records_rate_total[5m])) by (database)",
          "legendFormat": "{{database}}"
        }
      ]
    },
    {
      "title": "ç´¯è®¡å¤„ç†è®°å½•æ•°",
      "type": "stat", 
      "targets": [
        {
          "expr": "sum(batchflow_records_rate_total)",
          "legendFormat": "æ€»è®°å½•æ•°"
        }
      ]
    }
  ]
}
```

#### 2. æ•°æ®å®Œæ•´æ€§é¢æ¿

```json
{
  "title": "æ•°æ®å®Œæ•´æ€§ç›‘æ§",
  "panels": [
    {
      "title": "æ•°æ®å®Œæ•´æ€§ç‡",
      "type": "table",
      "targets": [
        {
          "expr": "batchflow_data_integrity_rate * 100",
          "format": "table",
          "legendFormat": "{{database}} - {{test_name}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "percent",
          "thresholds": {
            "steps": [
              {"color": "red", "value": 0},
              {"color": "yellow", "value": 95},
              {"color": "green", "value": 99}
            ]
          }
        }
      }
    }
  ]
}
```

#### 3. æ€§èƒ½è¶‹åŠ¿é¢æ¿

```json
{
  "title": "æ€§èƒ½è¶‹åŠ¿åˆ†æ",
  "panels": [
    {
      "title": "RPS è¶‹åŠ¿",
      "type": "timeseries",
      "targets": [
        {
          "expr": "batchflow_current_rps",
          "legendFormat": "å½“å‰ RPS - {{database}} - {{test_name}}"
        },
        {
          "expr": "rate(batchflow_records_rate_total[5m])",
          "legendFormat": "å¹³å‡ RPS (5m) - {{database}} - {{test_name}}"
        }
      ]
    },
    {
      "title": "æ‰¹æ¬¡æ‰§è¡Œè€—æ—¶",
      "type": "timeseries", 
      "targets": [
        {
          "expr": "histogram_quantile(0.95, batchflow_batch_execution_duration_ms_bucket)",
          "legendFormat": "P95 - {{database}}"
        },
        {
          "expr": "histogram_quantile(0.50, batchflow_batch_execution_duration_ms_bucket)",
          "legendFormat": "P50 - {{database}}"
        }
      ]
    }
  ]
}
```

### å®Œæ•´é¢æ¿å¯¼å…¥

```bash
# å¯¼å…¥é¢„é…ç½®çš„ Grafana é¢æ¿
curl -X POST \
  http://admin:admin@localhost:3000/api/dashboards/db \
  -H 'Content-Type: application/json' \
  -d @test/integration/grafana/provisioning/dashboards/batchflow-performance.json
```

## ğŸ” ç›‘æ§æŸ¥è¯¢ç¤ºä¾‹

### Prometheus æŸ¥è¯¢è¯­å¥

#### æ€§èƒ½åˆ†ææŸ¥è¯¢

```promql
# å„æ•°æ®åº“çš„å½“å‰ RPSï¼ˆç¬æ—¶å€¼ï¼‰
avg(batchflow_current_rps) by (database)

# æœ€è¿‘5åˆ†é’Ÿçš„å¹³å‡ RPSï¼ˆæ¨èç”¨äºè¶‹åŠ¿åˆ†æï¼‰
rate(batchflow_records_rate_total[5m])

# æœ€è¿‘1åˆ†é’Ÿçš„ RPSï¼ˆæ›´æ•æ„Ÿçš„ç›‘æ§ï¼‰
rate(batchflow_records_rate_total[1m])

# å„æ•°æ®åº“çš„ RPS å¯¹æ¯”
sum(rate(batchflow_records_rate_total[5m])) by (database)

# æ‰¹æ¬¡æ‰§è¡Œè€—æ—¶çš„95åˆ†ä½æ•°
histogram_quantile(0.95, rate(batchflow_batch_execution_duration_ms_bucket[5m]))

# é”™è¯¯ç‡è¶‹åŠ¿
rate(batchflow_batch_failed_total[5m]) / rate(batchflow_batch_success_total[5m] + batchflow_batch_failed_total[5m])
```

#### å®¹é‡è§„åˆ’æŸ¥è¯¢

```promql
# å†…å­˜ä½¿ç”¨è¶‹åŠ¿
batchflow_memory_usage_mb  # å·²ç»æ˜¯ MB å•ä½ï¼Œæ— éœ€è½¬æ¢

# ç¼“å†²åŒºåˆ©ç”¨ç‡
avg(batchflow_buffer_utilization) by (database, test_name)

# è¿æ¥æ± ä½¿ç”¨æƒ…å†µ
batchflow_active_connections / on(database) group_left() max_connections
```

#### æ•°æ®è´¨é‡æŸ¥è¯¢

```promql
# æ•°æ®å®Œæ•´æ€§ä½äº99%çš„æµ‹è¯•
batchflow_data_integrity_rate < 0.99

# å„æ•°æ®åº“çš„æ•°æ®å®Œæ•´æ€§å¯¹æ¯”
batchflow_data_integrity_rate * 100

# æ•°æ®å®Œæ•´æ€§å˜åŒ–è¶‹åŠ¿
delta(batchflow_data_integrity_rate[1h])
```

## ğŸš¨ å‘Šè­¦é…ç½®

### Prometheus å‘Šè­¦è§„åˆ™

```yaml
# prometheus/alert_rules.yml
groups:
  - name: batchflow_alerts
    rules:
      - alert: BatchFlowHighErrorRate
        expr: rate(batchflow_batch_failed_total[5m]) / rate(batchflow_batch_success_total[5m] + batchflow_batch_failed_total[5m]) > 0.05
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "BatchFlow é”™è¯¯ç‡è¿‡é«˜"
          description: "æ•°æ®åº“ {{ $labels.database }} çš„é”™è¯¯ç‡ä¸º {{ $value | humanizePercentage }}"
      
      - alert: BatchFlowLowDataIntegrity
        expr: batchflow_data_integrity_rate < 0.95
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "BatchFlow æ•°æ®å®Œæ•´æ€§å¼‚å¸¸"
          description: "æµ‹è¯• {{ $labels.test_name }} çš„æ•°æ®å®Œæ•´æ€§ä»…ä¸º {{ $value | humanizePercentage }}"
      
      - alert: BatchFlowLowPerformance
        expr: batchflow_current_rps < 1000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "BatchFlow æ€§èƒ½ä¸‹é™"
          description: "æ•°æ®åº“ {{ $labels.database }} çš„ RPS é™è‡³ {{ $value }}"
      
      - alert: BatchFlowHighMemoryUsage
        expr: batchflow_memory_usage_bytes > 1073741824  # 1GB
        for: 3m
        labels:
          severity: warning
        annotations:
          summary: "BatchFlow å†…å­˜ä½¿ç”¨è¿‡é«˜"
          description: "å†…å­˜ä½¿ç”¨é‡è¾¾åˆ° {{ $value | humanizeBytes }}"
```

### Grafana å‘Šè­¦é…ç½®

```json
{
  "alert": {
    "name": "æ•°æ®å®Œæ•´æ€§å‘Šè­¦",
    "message": "BatchFlow æ•°æ®å®Œæ•´æ€§ä½äºé˜ˆå€¼",
    "frequency": "10s",
    "conditions": [
      {
        "query": {
          "queryType": "",
          "refId": "A",
          "model": {
            "expr": "batchflow_data_integrity_rate * 100",
            "interval": "",
            "legendFormat": "",
            "refId": "A"
          }
        },
        "reducer": {
          "type": "last",
          "params": []
        },
        "evaluator": {
          "params": [95],
          "type": "lt"
        }
      }
    ],
    "executionErrorState": "alerting",
    "noDataState": "no_data",
    "for": "1m"
  }
}
```

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰æŒ‡æ ‡æ”¶é›†å™¨

```go
type CustomMetricsCollector struct {
    prometheus *PrometheusMetrics
    database   string
    testName   string
    
    // è‡ªå®šä¹‰æŒ‡æ ‡
    customCounter   prometheus.Counter
    customHistogram prometheus.Histogram
}

func NewCustomMetricsCollector(pm *PrometheusMetrics, database, testName string) *CustomMetricsCollector {
    collector := &CustomMetricsCollector{
        prometheus: pm,
        database:   database,
        testName:   testName,
    }
    
    // æ³¨å†Œè‡ªå®šä¹‰æŒ‡æ ‡
    collector.customCounter = prometheus.NewCounter(prometheus.CounterOpts{
        Name: "batchflow_custom_operations_total",
        Help: "Total number of custom operations",
    })
    
    collector.customHistogram = prometheus.NewHistogram(prometheus.HistogramOpts{
        Name:    "batchflow_custom_duration_seconds",
        Help:    "Duration of custom operations",
        Buckets: prometheus.DefBuckets,
    })
    
    prometheus.MustRegister(collector.customCounter, collector.customHistogram)
    
    return collector
}

func (c *CustomMetricsCollector) RecordCustomOperation(duration time.Duration) {
    c.customCounter.Inc()
    c.customHistogram.Observe(duration.Seconds())
}
```

### å¤šç¯å¢ƒç›‘æ§é…ç½®

```go
type EnvironmentConfig struct {
    Name              string
    PrometheusPort    int
    GrafanaURL        string
    AlertManagerURL   string
    MetricsPrefix     string
}

func SetupMonitoringForEnvironment(env EnvironmentConfig) *PrometheusMetrics {
    // åˆ›å»ºå¸¦ç¯å¢ƒæ ‡è¯†çš„æŒ‡æ ‡æ”¶é›†å™¨
    prometheusMetrics := NewPrometheusMetrics()
    prometheusMetrics.SetEnvironment(env.Name)
    prometheusMetrics.SetMetricsPrefix(env.MetricsPrefix)
    
    // å¯åŠ¨æŒ‡æ ‡æœåŠ¡å™¨
    go prometheusMetrics.StartServer(env.PrometheusPort)
    
    // é…ç½®å‘Šè­¦
    if env.AlertManagerURL != "" {
        prometheusMetrics.ConfigureAlertManager(env.AlertManagerURL)
    }
    
    return prometheusMetrics
}

// ä½¿ç”¨ç¤ºä¾‹
func main() {
    envs := []EnvironmentConfig{
        {Name: "production", PrometheusPort: 9090, MetricsPrefix: "prod_"},
        {Name: "staging", PrometheusPort: 9091, MetricsPrefix: "staging_"},
        {Name: "development", PrometheusPort: 9092, MetricsPrefix: "dev_"},
    }
    
    for _, env := range envs {
        metrics := SetupMonitoringForEnvironment(env)
        defer metrics.StopServer()
    }
}
```

## ğŸ“Š ç›‘æ§æœ€ä½³å®è·µ

### 1. æŒ‡æ ‡å‘½åè§„èŒƒ

```go
// âœ… å¥½çš„å‘½å
batchflow_records_processed_total
batchflow_batch_execution_duration_ms
batchflow_data_integrity_rate

// âŒ é¿å…çš„å‘½å
records_count
duration
integrity
```

### 2. æ ‡ç­¾ä½¿ç”¨åŸåˆ™

```go
// âœ… åˆç†çš„æ ‡ç­¾
labels := map[string]string{
    "database":  "mysql",      // æ•°æ®åº“ç±»å‹
    "table":     "users",      // è¡¨å
    "test_name": "batch_insert", // æµ‹è¯•åç§°
    "env":       "production", // ç¯å¢ƒ
}

// âŒ é¿å…é«˜åŸºæ•°æ ‡ç­¾
labels := map[string]string{
    "record_id": "12345",     // ä¼šäº§ç”Ÿå¤§é‡æ—¶é—´åºåˆ—
    "timestamp": "1609459200", // æ—¶é—´æˆ³ä¸åº”ä½œä¸ºæ ‡ç­¾
}
```

### 3. ç›‘æ§æ•°æ®ä¿ç•™ç­–ç•¥

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

scrape_configs:
  - job_name: 'batchflow'
    static_configs:
      - targets: ['localhost:9090']
    scrape_interval: 5s
    metrics_path: /metrics

# æ•°æ®ä¿ç•™é…ç½®
storage:
  tsdb:
    retention.time: 30d
    retention.size: 10GB
```

### 4. æ€§èƒ½ä¼˜åŒ–å»ºè®®

```go
// æ‰¹é‡æ›´æ–°æŒ‡æ ‡ï¼Œå‡å°‘é”ç«äº‰
func (pm *PrometheusMetrics) BatchUpdateMetrics(updates []MetricUpdate) {
    pm.mu.Lock()
    defer pm.mu.Unlock()
    
    for _, update := range updates {
        switch update.Type {
        case "counter":
            pm.counters[update.Name].Add(update.Value)
        case "gauge":
            pm.gauges[update.Name].Set(update.Value)
        case "histogram":
            pm.histograms[update.Name].Observe(update.Value)
        }
    }
}

// ä½¿ç”¨ç¼“å†²åŒºå‡å°‘æŒ‡æ ‡æ›´æ–°é¢‘ç‡
type MetricsBuffer struct {
    updates []MetricUpdate
    size    int
    mu      sync.Mutex
}

func (mb *MetricsBuffer) Add(update MetricUpdate) {
    mb.mu.Lock()
    defer mb.mu.Unlock()
    
    mb.updates = append(mb.updates, update)
    
    if len(mb.updates) >= mb.size {
        mb.flush()
    }
}
```

## ğŸ” æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. æŒ‡æ ‡æ•°æ®ç¼ºå¤±

**ç—‡çŠ¶**ï¼šGrafana é¢æ¿æ˜¾ç¤º "No data"

**æ’æŸ¥æ­¥éª¤**ï¼š
```bash
# æ£€æŸ¥ Prometheus ç›®æ ‡çŠ¶æ€
curl http://localhost:9090/api/v1/targets

# æ£€æŸ¥æŒ‡æ ‡æ˜¯å¦å­˜åœ¨
curl http://localhost:9090/api/v1/label/__name__/values | grep batchflow

# æ£€æŸ¥åº”ç”¨æŒ‡æ ‡ç«¯ç‚¹
curl http://localhost:9090/metrics | grep batchflow
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ç¡®è®¤åº”ç”¨æ­£ç¡®å¯åŠ¨æŒ‡æ ‡æœåŠ¡å™¨
- æ£€æŸ¥é˜²ç«å¢™å’Œç½‘ç»œè¿æ¥
- éªŒè¯ Prometheus é…ç½®æ–‡ä»¶

#### 2. æ•°æ®å®Œæ•´æ€§æŒ‡æ ‡å¼‚å¸¸

**ç—‡çŠ¶**ï¼šæ˜¾ç¤º 10000% æˆ–å…¶ä»–å¼‚å¸¸å€¼

**æ’æŸ¥æ­¥éª¤**ï¼š
```bash
# æ£€æŸ¥åŸå§‹æŒ‡æ ‡å€¼
curl -s http://localhost:9090/api/v1/query?query=batchflow_data_integrity_rate

# æ£€æŸ¥ Grafana æŸ¥è¯¢è¡¨è¾¾å¼
# åº”è¯¥æ˜¯ï¼šbatchflow_data_integrity_rate * 100
# è€Œä¸æ˜¯ï¼šbatchflow_data_integrity_rate * 10000
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ç¡®è®¤æŒ‡æ ‡èŒƒå›´ä¸º 0-1
- ä¿®æ­£ Grafana æŸ¥è¯¢è¡¨è¾¾å¼
- æ£€æŸ¥åº”ç”¨ä¸­çš„æŒ‡æ ‡è®¡ç®—é€»è¾‘

#### 3. æ€§èƒ½æŒ‡æ ‡ä¸å‡†ç¡®

**ç—‡çŠ¶**ï¼šRPS æ˜¾ç¤ºå¼‚å¸¸é«˜æˆ–å¼‚å¸¸ä½

**æ’æŸ¥æ­¥éª¤**ï¼š
```promql
# æ£€æŸ¥è®¡æ•°å™¨å¢é•¿ç‡
rate(batchflow_records_processed_total[1m])

# æŸ¥çœ‹ç´¯è®¡å¤„ç†è®°å½•æ•°ï¼ˆæ¨èï¼‰
sum by (database) (batchflow_records_processed_total{status="processed"})

# å¦‚éœ€æŸ¥çœ‹æ—¶é—´çª—å£å†…çš„å¢é‡
increase(batchflow_records_processed_total[5m])
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- è°ƒæ•´ PromQL æŸ¥è¯¢çš„æ—¶é—´çª—å£
- ç¡®è®¤è®¡æ•°å™¨æ­£ç¡®é€’å¢
- æ£€æŸ¥ç³»ç»Ÿæ—¶é’ŸåŒæ­¥

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [API_REFERENCE.md](API_REFERENCE.md) - WithMetricsReporter è¯¦ç»†ç”¨æ³•
- [EXAMPLES.md](EXAMPLES.md) - ç›‘æ§é›†æˆç¤ºä¾‹
- [TESTING_GUIDE.md](TESTING_GUIDE.md) - ç›‘æ§æµ‹è¯•æ–¹æ³•
- [TROUBLESHOOTING.md](TROUBLESHOOTING.md) - è¯¦ç»†æ•…éšœæ’æŸ¥

---

ğŸ’¡ **ç›‘æ§å»ºè®®**ï¼š
1. ä»æ ¸å¿ƒæŒ‡æ ‡å¼€å§‹ï¼Œé€æ­¥æ‰©å±•ç›‘æ§èŒƒå›´
2. è®¾ç½®åˆç†çš„å‘Šè­¦é˜ˆå€¼ï¼Œé¿å…å‘Šè­¦ç–²åŠ³
3. å®šæœŸå®¡æŸ¥å’Œä¼˜åŒ–ç›‘æ§é…ç½®
4. å»ºç«‹ç›‘æ§æ•°æ®çš„å¤‡ä»½å’Œæ¢å¤æœºåˆ¶